{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect if the outputs from the 10 random runs deviate significantly from each other. \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from netCDF4 import Dataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import r2_score as R2\n",
    "from sklearn.model_selection import KFold\n",
    "from copy import deepcopy\n",
    "import utils\n",
    "from unet import UNet_nobatchnorm\n",
    "from scipy.stats import pearsonr\n",
    "from pathlib import Path\n",
    "import numpy.fft as fft\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import helper_functions as hf\n",
    "from scipy.signal import convolve2d, convolve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/work/uo0780/u241359/project_tide_synergy/data/'\n",
    "nctrains, nctest = hf.load_data_from_nc_as_lists(root_dir)\n",
    "Ntrain = np.sum([nc.dimensions['time_counter'].size for nc in nctrains], axis = 0)\n",
    "Ntest = np.sum([nc.dimensions['time_counter'].size for nc in nctest], axis = 0)\n",
    "\n",
    "model_folder = '/work/uo0780/u241359/project_tide_synergy/trainedmodels_forpaper/'\n",
    "\n",
    "vel_cmap  = 'BrBG' #'viridis'\n",
    "vort_cmap = 'PRGn'\n",
    "ssh_cmap  = 'bwr'\n",
    "sst_cmap = 'inferno'\n",
    "\n",
    "bottom_slice = slice(0,256)\n",
    "mid_slice = slice(232, 488)\n",
    "top_slice = slice(464, 720)\n",
    "\n",
    "def corr(data, mod):\n",
    "    return pearsonr(data.flatten(), mod.flatten())[0]\n",
    "def L2_R(data,mod):\n",
    "    return R2(data.flatten(), mod.flatten())\n",
    "\n",
    "nensemble = 10 #How many re-trained U-Net models there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nbase = 16\n",
    "def totorch(x):\n",
    "    return torch.tensor(x, dtype = torch.float).cpu()\n",
    "    \n",
    "def preload_data(nctrains, total_records):\n",
    "    #total_records = Ntrain#sum(nc.dimensions['time_counter'].size for nc in nctrains)\n",
    "    #dimensions of data of the nc file.\n",
    "    max_height = 722\n",
    "    max_width = 258\n",
    "    all_input_data = np.zeros((total_records, N_inp, max_height, max_width))*np.nan\n",
    "    all_output_data = np.zeros((total_records, N_out, max_height, max_width))*np.nan\n",
    "    current_index = 0\n",
    "    for ncindex, ncdata in enumerate(nctrains):\n",
    "        num_recs = ncdata.dimensions['time_counter'].size\n",
    "        rec_slice = slice(current_index, current_index + num_recs)\n",
    "        \n",
    "        for ind, var_name in enumerate(var_input_names):\n",
    "            data_slice = np.squeeze(ncdata.variables[var_name])\n",
    "            # print('data_slice shape:')\n",
    "            # print(data_slice.shape)        \n",
    "            #all_input_data[rec_slice, ind, :, :] = data_slice\n",
    "            #For some variables, the dimensions in (x, y) may be smaller than (max_height, max_width). Changing the code so that it adapts them.\n",
    "            # Get the actual dimensions of data_slice\n",
    "            slice_height, slice_width = data_slice.shape[-2], data_slice.shape[-1]\n",
    "            # Place data_slice into the corresponding slice of all_input_data\n",
    "            all_input_data[rec_slice, ind, :slice_height, :slice_width] = data_slice\n",
    "    \n",
    "\n",
    "        for ind, var_name in enumerate(var_output_names):\n",
    "            data_slice = np.squeeze(ncdata.variables[var_name])\n",
    "            #all_output_data[rec_slice, ind, :, :] = data_slice\n",
    "            # Get the actual dimensions of data_slice\n",
    "            slice_height, slice_width = data_slice.shape[-2], data_slice.shape[-1]\n",
    "            # Place data_slice into the corresponding slice of all_input_data\n",
    "            all_output_data[rec_slice, ind, :slice_height, :slice_width] = data_slice\n",
    "\n",
    "        current_index += num_recs\n",
    "        \n",
    "    return all_input_data, all_output_data\n",
    "\n",
    "# # Modify the loadtrain function to pull data from preloaded memory\n",
    "# def loaddata_preloaded_train(index, batch_size, all_input_data, all_output_data):\n",
    "#     rec_slice = slice(index, index + batch_size)\n",
    "#     lim = 720\n",
    "#     width = 256\n",
    "#     yslice = slice(0, lim)\n",
    "#     xslice = slice(0, width)\n",
    "#     # print('rec_slice is:')\n",
    "#     # print(rec_slice)\n",
    "#     # print('mean of squared values of loaded input data:')\n",
    "#     # print(\"{0:0.32f}\".format(np.nanmean(all_input_data[rec_slice, :, yslice, xslice]**2)))\n",
    "#     return (all_input_data[rec_slice, :, yslice, xslice], \n",
    "#             all_output_data[rec_slice, :, yslice, xslice])\n",
    "#Load test data as one single batch\n",
    "def loaddata_preloaded_test(all_input_data, all_output_data):\n",
    "    #rec_slice = slice(index, index + batch_size)\n",
    "    lim = 720\n",
    "    width = 256\n",
    "    yslice = slice(0, lim)\n",
    "    xslice = slice(0, width)\n",
    "    # print('rec_slice is:')\n",
    "    # print(rec_slice)\n",
    "    # print('mean of squared values of loaded input data:')\n",
    "    # print(\"{0:0.32f}\".format(np.nanmean(all_input_data[rec_slice, :, yslice, xslice]**2)))\n",
    "    return (all_input_data[:, :, yslice, xslice], \n",
    "            all_output_data[:, :, yslice, xslice])\n",
    "\n",
    "\n",
    "def load_variable(ncdata, ncindex, variable, rec_slice, yslice, xslice):\n",
    "    data_squeezed = np.squeeze(ncdata[ncindex].variables[variable])\n",
    "    return data_squeezed[rec_slice, yslice, xslice]\n",
    "\n",
    "def hwvorticity(u, v, dgrid = 4000):\n",
    "    return (np.gradient(v, axis =2) - np.gradient(u, axis =1))/dgrid\n",
    "\n",
    "def hwdivergence(u, v, dgrid = 4000):\n",
    "    return (np.gradient(u, axis =2) + np.gradient(v, axis =1))/dgrid\n",
    "\n",
    "def preload_data_vortdiv(nctrains, total_records):\n",
    "    #total_records = Ntrain#sum(nc.dimensions['time_counter'].size for nc in nctrains)\n",
    "    #dimensions of data of the nc file.\n",
    "    max_height = 722\n",
    "    max_width = 258\n",
    "    all_input_data = np.zeros((total_records, N_inp, max_height, max_width))*np.nan\n",
    "    all_output_data = np.zeros((total_records, N_out, max_height, max_width))*np.nan\n",
    "    current_index = 0\n",
    "    for ncindex, ncdata in enumerate(nctrains):\n",
    "        num_recs = ncdata.dimensions['time_counter'].size #how many time stamps are there in each .nc file (i.e., at each turbulence level)\n",
    "        rec_slice = slice(current_index, current_index + num_recs)\n",
    "        for ind, var_name in enumerate(var_input_names):\n",
    "            if var_name == 'vort':\n",
    "                u = np.squeeze(ncdata.variables['u_xy_ins'])\n",
    "                v = np.squeeze(ncdata.variables['v_xy_ins'])\n",
    "                #u.shape: (150, 722, 257); v.shape: (150, 721, 258)\n",
    "                #as u and v have different number of grid points in x and y, we truncate them so that their shapes agree, enabling the simple way to compute vorticities based on finite diff.\n",
    "                data_slice = hwvorticity(u[:,:-1,:], v[:,:,:-1])\n",
    "            elif var_name == 'div':\n",
    "                u = np.squeeze(ncdata.variables['u_xy_ins'])\n",
    "                v = np.squeeze(ncdata.variables['v_xy_ins'])\n",
    "                data_slice = hwdivergence(u[:,:-1,:], v[:,:,:-1])\n",
    "            else:           \n",
    "                data_slice = np.squeeze(ncdata.variables[var_name])\n",
    "            # print('data_slice shape:')\n",
    "            # print(data_slice.shape)        \n",
    "            #all_input_data[rec_slice, ind, :, :] = data_slice\n",
    "            \n",
    "            #For some variables, the dimensions in (x, y) may be smaller than (max_height, max_width). Changing the code so that it adapts them.\n",
    "            # Get the actual dimensions of data_slice\n",
    "            slice_height, slice_width = data_slice.shape[-2], data_slice.shape[-1]\n",
    "            # Place data_slice into the corresponding slice of all_input_data\n",
    "            all_input_data[rec_slice, ind, :slice_height, :slice_width] = data_slice\n",
    "    \n",
    "\n",
    "        for ind, var_name in enumerate(var_output_names):\n",
    "            data_slice = np.squeeze(ncdata.variables[var_name])\n",
    "            #all_output_data[rec_slice, ind, :, :] = data_slice\n",
    "            # Get the actual dimensions of data_slice\n",
    "            slice_height, slice_width = data_slice.shape[-2], data_slice.shape[-1]\n",
    "            # Place data_slice into the corresponding slice of all_input_data\n",
    "            all_output_data[rec_slice, ind, :slice_height, :slice_width] = data_slice\n",
    "\n",
    "        current_index += num_recs\n",
    "        \n",
    "    return all_input_data, all_output_data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for low-pass filtering\n",
    "def gaussian_kernel(decaylength): \n",
    "    \"\"\"Generates a Gaussian kernel.\"\"\"\n",
    "    #decaylength is in the unit of grid resolution (4km in Aurelien's data.) So in physical units, the decay lenght would be decaylength*(4 km).\n",
    "    size=int(2*decaylength)\n",
    "    sigma=decaylength/(2*np.sqrt(2*np.log(2))) #Interpretting decaylength as the FWHM of Gaussian\n",
    "    kernel = np.fromfunction(\n",
    "        lambda x, y: (1 / np.sqrt(2 * np.pi * sigma ** 2)) * \n",
    "                      np.exp(-((x- size/2)**2 + (y-size/2)**2) / (2 * sigma ** 2)),\n",
    "        (size, size)  \n",
    "    ) #Creating a kernel with \n",
    "    return kernel / np.sum(kernel)  # Normalize the kernel\n",
    "    \n",
    "def degrade_space_gaussian(field, decaylength):\n",
    "    nt, nx, ny = np.shape(field)\n",
    "    kernel = gaussian_kernel(decaylength)\n",
    "    filtered_field = np.empty([nt, nx, ny])\n",
    "\n",
    "    for i in range(nt):\n",
    "        filtered_field[i, : ,:] = convolve2d(field[i, : ,:], kernel, mode = 'same', boundary='symm')#,  fillvalue = np.average(field[i, : ,:]))\n",
    "    return filtered_field\n",
    "\n",
    "# Load all data into memory; no normalization is done here yet.\n",
    "# Apply a spatial lowpass filter to the temperature field 'T_xy_ins'\n",
    "# decayunits is how many units of grid spacing is the decay length scale. A grid spacing is 4km in Aurelien's data. So in physical units, the decay lenght would be decayunits*(4 km).\n",
    "def preload_data_filterT(nctrains, total_records,decayunits=25,plot=True):\n",
    "    #total_records = Ntrain#sum(nc.dimensions['time_counter'].size for nc in nctrains)\n",
    "    #dimensions of data of the nc file.\n",
    "    max_height = 722\n",
    "    max_width = 258\n",
    "    all_input_data = np.zeros((total_records, N_inp, max_height, max_width))*np.nan\n",
    "    all_output_data = np.zeros((total_records, N_out, max_height, max_width))*np.nan\n",
    "    current_index = 0\n",
    "    for ncindex, ncdata in enumerate(nctrains):\n",
    "        num_recs = ncdata.dimensions['time_counter'].size\n",
    "        rec_slice = slice(current_index, current_index + num_recs)\n",
    "        \n",
    "        for ind, var_name in enumerate(var_input_names):\n",
    "            data_slice = np.squeeze(ncdata.variables[var_name])\n",
    "            # print('data_slice shape:')\n",
    "            # print(data_slice.shape)        \n",
    "            #Turns out to be (time, height, width)\n",
    "            # print('var_name:')\n",
    "            # print(var_name)\n",
    "            # Apply lowpass filter when the field is 'T_xy_ins'\n",
    "            if var_name == 'T_xy_ins':\n",
    "                if plot == True:\n",
    "                    #Plot an image before the filter\n",
    "                    itime=20        \n",
    "                    cmapmax=np.max(data_slice[itime,:,:])\n",
    "                    cmapmin=np.min(data_slice[itime,:,:])\n",
    "                    figT, axT = plt.subplots(1, 2, figsize=(5, 5))\n",
    "                    figT.set_dpi(256)   \n",
    "                    im0=axT[0].pcolor(data_slice[itime,:,:],vmin=cmapmin,vmax=cmapmax)\n",
    "                    axT[0].set_aspect(1)\n",
    "                #Lowpass filter\n",
    "                data_slice=degrade_space_gaussian(data_slice,decayunits)\n",
    "                if plot == True:\n",
    "                    axT[1].pcolor(data_slice[itime,:,:],vmin=cmapmin,vmax=cmapmax)\n",
    "                    axT[1].set_aspect(1)\n",
    "                    cbar0=plt.colorbar(im0, ax=axT, fraction=0.046, pad=0.04)\n",
    "            \n",
    "            #For some variables, the dimensions in (x, y) may be smaller than (max_height, max_width). Changing the code so that it adapts them.\n",
    "            # Get the actual dimensions of data_slice\n",
    "            slice_height, slice_width = data_slice.shape[-2], data_slice.shape[-1]\n",
    "            # Place data_slice into the corresponding slice of all_input_data\n",
    "            all_input_data[rec_slice, ind, :slice_height, :slice_width] = data_slice\n",
    "    \n",
    "\n",
    "        for ind, var_name in enumerate(var_output_names):\n",
    "            data_slice = np.squeeze(ncdata.variables[var_name])\n",
    "            if var_name == 'T_xy_ins':\n",
    "                if plot == True:\n",
    "                    #Plot an image before the filter\n",
    "                    itime=20        \n",
    "                    cmapmax=np.max(data_slice[itime,:,:])\n",
    "                    cmapmin=np.min(data_slice[itime,:,:])\n",
    "                    figT, axT = plt.subplots(1, 2, figsize=(5, 5))\n",
    "                    figT.set_dpi(256)   \n",
    "                    im0=axT[0].pcolor(data_slice[itime,:,:],vmin=cmapmin,vmax=cmapmax)\n",
    "                    axT[0].set_aspect(1)\n",
    "                #Lowpass filter\n",
    "                \n",
    "                data_slice=degrade_space_gaussian(data_slice,decayunits)\n",
    "                if plot == True:\n",
    "                    axT[1].pcolor(data_slice[itime,:,:],vmin=cmapmin,vmax=cmapmax)\n",
    "                    axT[1].set_aspect(1)\n",
    "                    cbar0=plt.colorbar(im0, ax=axT, fraction=0.046, pad=0.04)\n",
    "            #all_output_data[rec_slice, ind, :, :] = data_slice\n",
    "            # Get the actual dimensions of data_slice\n",
    "            slice_height, slice_width = data_slice.shape[-2], data_slice.shape[-1]\n",
    "            # Place data_slice into the corresponding slice of all_input_data\n",
    "            all_output_data[rec_slice, ind, :slice_height, :slice_width] = data_slice\n",
    "\n",
    "        current_index += num_recs\n",
    "        \n",
    "    return all_input_data, all_output_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_389418/3781206836.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3781206836.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3781206836.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3781206836.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3781206836.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3781206836.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3781206836.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3781206836.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3781206836.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3781206836.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full panel, correlation:\n",
      ", full & 0.8394 & 0.8432 & 0.8341 & 0.0028 \\\\\n",
      "full panel, R2:\n",
      ", full & 0.7036 & 0.7093 & 0.6957 & 0.0043 \\\\\n",
      "midjet panel, correlation:\n",
      ", mid & 0.7616 & 0.7676 & 0.7521 & 0.0053 \\\\\n",
      "midjet panel, R2:\n",
      ", mid & 0.5797 & 0.5888 & 0.5654 & 0.0080 \\\\\n"
     ]
    }
   ],
   "source": [
    "# ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ Change below for each Configuration ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
    "decayunits=25 #The best SST satellite has a resolution of 9 km. It may be safe to set decayunits to be 20 km to be already resolvable by satellites\n",
    "\n",
    "vi1 = 'ssh_ins'\n",
    "vi2 = 'T_xy_ins'\n",
    "\n",
    "vo1 = 'ssh_cos'\n",
    "vo2 = 'ssh_sin'\n",
    "\n",
    "batch_size = 80 #maximizing it so that the GPU memory maxes out. Needs to be divisible by Ntrain. Otherwise there will be size mismatch issues.\n",
    "lr0 = 0.005*10/batch_size #Roughly should scale inversely to batch_size\n",
    "\n",
    "var_input_names = [vi1, vi2]\n",
    "var_output_names = [vo1, vo2]\n",
    "N_inp = len(var_input_names)\n",
    "N_out = len(var_output_names)\n",
    "\n",
    "save_fn_prefix  = 'any_{}{}_{}{}_nobatchnorm_degradeT_du_{}'.format(vi1, vi2, vo1, vo2, decayunits)\n",
    "# ↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑\n",
    "nctrains, nctest = hf.load_data_from_nc_as_lists(root_dir)\n",
    "\n",
    "all_train_input, all_train_output = preload_data_filterT(nctrains, Ntrain, decayunits=decayunits,plot=False)\n",
    "all_test_input, all_test_output = preload_data_filterT(nctest, Ntest, decayunits=decayunits,plot=False)\n",
    "\n",
    "#Normalize data\n",
    "#Compute mean and variance for normalization\n",
    "mean_input=np.nanmean(np.concatenate((all_train_input, all_test_input), axis=0),axis=(0, 2, 3))\n",
    "mean_output=np.nanmean(np.concatenate((all_train_output, all_test_output), axis=0),axis=(0, 2, 3))\n",
    "#Subtract the data with their means\n",
    "all_train_input=all_train_input-mean_input[None, :, None, None]\n",
    "all_train_output=all_train_output-mean_output[None, :, None, None]\n",
    "all_test_input=all_test_input-mean_input[None, :, None, None]\n",
    "all_test_output=all_test_output-mean_output[None, :, None, None]\n",
    "#Compute the variances\n",
    "var_input=np.nanmean((np.concatenate((all_train_input, all_test_input), axis=0))**2,axis=(0, 2, 3))\n",
    "var_output=np.nanmean((np.concatenate((all_train_output, all_test_output), axis=0))**2,axis=(0, 2, 3))\n",
    "#Scale the data so that they have variance of 1\n",
    "all_train_input=all_train_input/np.sqrt(var_input[None, :, None, None])\n",
    "all_train_output=all_train_output/np.sqrt(var_output[None, :, None, None])\n",
    "all_test_input=all_test_input/np.sqrt(var_input[None, :, None, None])\n",
    "all_test_output=all_test_output/np.sqrt(var_output[None, :, None, None])\n",
    "\n",
    "inp_test, out_test = loaddata_preloaded_test(all_test_input, all_test_output)\n",
    "out_test = out_test*np.sqrt(var_output[None, :, None, None])+mean_output[None, :, None, None]\n",
    "\n",
    "truth_bot = out_test[:, :, bottom_slice, :]\n",
    "truth_mid = out_test[:, :, mid_slice, :]\n",
    "truth_top = out_test[:, :, top_slice, :]\n",
    "\n",
    "combined_names = ''.join(var_input_names)\n",
    "\n",
    "#Array to record performance metrics\n",
    "corr_ensemble_full = np.zeros(nensemble)\n",
    "R2_ensemble_full = np.zeros(nensemble)\n",
    "corr_ensemble_top = np.zeros(nensemble)\n",
    "R2_ensemble_top = np.zeros(nensemble)\n",
    "corr_ensemble_mid = np.zeros(nensemble)\n",
    "R2_ensemble_mid = np.zeros(nensemble)\n",
    "corr_ensemble_bot = np.zeros(nensemble)\n",
    "R2_ensemble_bot = np.zeros(nensemble)\n",
    "for iensemble in np.arange(nensemble):\n",
    "    fstr = f'{save_fn_prefix}_rp_{iensemble}' \n",
    "    model_filename = f'/{fstr}.pth'\n",
    "    model_path = model_folder+ model_filename\n",
    "    state_dict = torch.load(model_path)\n",
    "    # Create a new instance of the model\n",
    "    model = UNet_nobatchnorm(N_inp, N_out, bilinear = True, Nbase = Nbase)\n",
    "    # Load the state_dict into the model\n",
    "    model.load_state_dict(state_dict)\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out_mod = model(totorch(inp_test)).detach().cpu().numpy()\n",
    "    #Renormalize\n",
    "    out_mod = out_mod*np.sqrt(var_output[None, :, None, None])+mean_output[None, :, None, None]\n",
    "\n",
    "    mod_bot = out_mod[:, :, bottom_slice, :]\n",
    "    mod_mid = out_mod[:, :, mid_slice, :]\n",
    "    mod_top = out_mod[:, :, top_slice, :]\n",
    "\n",
    "    corr_ensemble_full[iensemble] = corr(out_test, out_mod)\n",
    "    R2_ensemble_full[iensemble] = L2_R(out_test, out_mod)    \n",
    "    corr_ensemble_top[iensemble] = corr(truth_top, mod_top)\n",
    "    R2_ensemble_top[iensemble] = L2_R(truth_top, mod_top)  \n",
    "    corr_ensemble_mid[iensemble] = corr(truth_mid, mod_mid)\n",
    "    R2_ensemble_mid[iensemble] = L2_R(truth_mid, mod_mid)\n",
    "    corr_ensemble_bot[iensemble] = corr(truth_bot, mod_bot)\n",
    "    R2_ensemble_bot[iensemble] = L2_R(truth_bot, mod_bot)\n",
    "\n",
    "print('full panel, correlation:')\n",
    "mean_val = np.mean(corr_ensemble_full)\n",
    "max_val = np.max(corr_ensemble_full)\n",
    "min_val = np.min(corr_ensemble_full)\n",
    "std_val = np.std(corr_ensemble_full)\n",
    "latex_table_row=f', full & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)\n",
    "print('full panel, R2:')\n",
    "mean_val = np.mean(R2_ensemble_full)\n",
    "max_val = np.max(R2_ensemble_full)\n",
    "min_val = np.min(R2_ensemble_full)\n",
    "std_val = np.std(R2_ensemble_full)\n",
    "latex_table_row=f', full & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)\n",
    "print('midjet panel, correlation:')\n",
    "mean_val = np.mean(corr_ensemble_mid)\n",
    "max_val = np.max(corr_ensemble_mid)\n",
    "min_val = np.min(corr_ensemble_mid)\n",
    "std_val = np.std(corr_ensemble_mid)\n",
    "latex_table_row=f', mid & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)\n",
    "print('midjet panel, R2:')\n",
    "mean_val = np.mean(R2_ensemble_mid)\n",
    "max_val = np.max(R2_ensemble_mid)\n",
    "min_val = np.min(R2_ensemble_mid)\n",
    "std_val = np.std(R2_ensemble_mid)\n",
    "latex_table_row=f', mid & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_389418/3634441954.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3634441954.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3634441954.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3634441954.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3634441954.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3634441954.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3634441954.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3634441954.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3634441954.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3634441954.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full panel, correlation:\n",
      ", full & 0.8556 & 0.8628 & 0.8486 & 0.0042 \\\\\n",
      "full panel, R2:\n",
      ", full & 0.7309 & 0.7434 & 0.7199 & 0.0073 \\\\\n",
      "midjet panel, correlation:\n",
      ", mid & 0.7897 & 0.8012 & 0.7788 & 0.0068 \\\\\n",
      "midjet panel, R2:\n",
      ", mid & 0.6231 & 0.6416 & 0.6064 & 0.0106 \\\\\n"
     ]
    }
   ],
   "source": [
    "# ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ Change below for each Configuration ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
    "decayunits=5 #The best SST satellite has a resolution of 9 km. It may be safe to set decayunits to be 20 km to be already resolvable by satellites\n",
    "\n",
    "vi1 = 'ssh_ins'\n",
    "vi2 = 'T_xy_ins'\n",
    "\n",
    "vo1 = 'ssh_cos'\n",
    "vo2 = 'ssh_sin'\n",
    "\n",
    "batch_size = 80 #maximizing it so that the GPU memory maxes out. Needs to be divisible by Ntrain. Otherwise there will be size mismatch issues.\n",
    "lr0 = 0.005*10/batch_size #Roughly should scale inversely to batch_size\n",
    "\n",
    "var_input_names = [vi1, vi2]\n",
    "var_output_names = [vo1, vo2]\n",
    "N_inp = len(var_input_names)\n",
    "N_out = len(var_output_names)\n",
    "\n",
    "save_fn_prefix  = 'any_{}{}_{}{}_nobatchnorm_degradeT_du_{}'.format(vi1, vi2, vo1, vo2, decayunits)\n",
    "# ↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑\n",
    "nctrains, nctest = hf.load_data_from_nc_as_lists(root_dir)\n",
    "\n",
    "all_train_input, all_train_output = preload_data_filterT(nctrains, Ntrain, decayunits=decayunits,plot=False)\n",
    "all_test_input, all_test_output = preload_data_filterT(nctest, Ntest, decayunits=decayunits,plot=False)\n",
    "\n",
    "#Normalize data\n",
    "#Compute mean and variance for normalization\n",
    "mean_input=np.nanmean(np.concatenate((all_train_input, all_test_input), axis=0),axis=(0, 2, 3))\n",
    "mean_output=np.nanmean(np.concatenate((all_train_output, all_test_output), axis=0),axis=(0, 2, 3))\n",
    "#Subtract the data with their means\n",
    "all_train_input=all_train_input-mean_input[None, :, None, None]\n",
    "all_train_output=all_train_output-mean_output[None, :, None, None]\n",
    "all_test_input=all_test_input-mean_input[None, :, None, None]\n",
    "all_test_output=all_test_output-mean_output[None, :, None, None]\n",
    "#Compute the variances\n",
    "var_input=np.nanmean((np.concatenate((all_train_input, all_test_input), axis=0))**2,axis=(0, 2, 3))\n",
    "var_output=np.nanmean((np.concatenate((all_train_output, all_test_output), axis=0))**2,axis=(0, 2, 3))\n",
    "#Scale the data so that they have variance of 1\n",
    "all_train_input=all_train_input/np.sqrt(var_input[None, :, None, None])\n",
    "all_train_output=all_train_output/np.sqrt(var_output[None, :, None, None])\n",
    "all_test_input=all_test_input/np.sqrt(var_input[None, :, None, None])\n",
    "all_test_output=all_test_output/np.sqrt(var_output[None, :, None, None])\n",
    "\n",
    "inp_test, out_test = loaddata_preloaded_test(all_test_input, all_test_output)\n",
    "out_test = out_test*np.sqrt(var_output[None, :, None, None])+mean_output[None, :, None, None]\n",
    "\n",
    "truth_bot = out_test[:, :, bottom_slice, :]\n",
    "truth_mid = out_test[:, :, mid_slice, :]\n",
    "truth_top = out_test[:, :, top_slice, :]\n",
    "\n",
    "combined_names = ''.join(var_input_names)\n",
    "\n",
    "#Array to record performance metrics\n",
    "corr_ensemble_full = np.zeros(nensemble)\n",
    "R2_ensemble_full = np.zeros(nensemble)\n",
    "corr_ensemble_top = np.zeros(nensemble)\n",
    "R2_ensemble_top = np.zeros(nensemble)\n",
    "corr_ensemble_mid = np.zeros(nensemble)\n",
    "R2_ensemble_mid = np.zeros(nensemble)\n",
    "corr_ensemble_bot = np.zeros(nensemble)\n",
    "R2_ensemble_bot = np.zeros(nensemble)\n",
    "for iensemble in np.arange(nensemble):\n",
    "    fstr = f'{save_fn_prefix}_rp_{iensemble}' \n",
    "    model_filename = f'/{fstr}.pth'\n",
    "    model_path = model_folder+ model_filename\n",
    "    state_dict = torch.load(model_path)\n",
    "    # Create a new instance of the model\n",
    "    model = UNet_nobatchnorm(N_inp, N_out, bilinear = True, Nbase = Nbase)\n",
    "    # Load the state_dict into the model\n",
    "    model.load_state_dict(state_dict)\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out_mod = model(totorch(inp_test)).detach().cpu().numpy()\n",
    "    #Renormalize\n",
    "    out_mod = out_mod*np.sqrt(var_output[None, :, None, None])+mean_output[None, :, None, None]\n",
    "\n",
    "    mod_bot = out_mod[:, :, bottom_slice, :]\n",
    "    mod_mid = out_mod[:, :, mid_slice, :]\n",
    "    mod_top = out_mod[:, :, top_slice, :]\n",
    "\n",
    "    corr_ensemble_full[iensemble] = corr(out_test, out_mod)\n",
    "    R2_ensemble_full[iensemble] = L2_R(out_test, out_mod)    \n",
    "    corr_ensemble_top[iensemble] = corr(truth_top, mod_top)\n",
    "    R2_ensemble_top[iensemble] = L2_R(truth_top, mod_top)  \n",
    "    corr_ensemble_mid[iensemble] = corr(truth_mid, mod_mid)\n",
    "    R2_ensemble_mid[iensemble] = L2_R(truth_mid, mod_mid)\n",
    "    corr_ensemble_bot[iensemble] = corr(truth_bot, mod_bot)\n",
    "    R2_ensemble_bot[iensemble] = L2_R(truth_bot, mod_bot)\n",
    "\n",
    "print('full panel, correlation:')\n",
    "mean_val = np.mean(corr_ensemble_full)\n",
    "max_val = np.max(corr_ensemble_full)\n",
    "min_val = np.min(corr_ensemble_full)\n",
    "std_val = np.std(corr_ensemble_full)\n",
    "latex_table_row=f', full & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)\n",
    "print('full panel, R2:')\n",
    "mean_val = np.mean(R2_ensemble_full)\n",
    "max_val = np.max(R2_ensemble_full)\n",
    "min_val = np.min(R2_ensemble_full)\n",
    "std_val = np.std(R2_ensemble_full)\n",
    "latex_table_row=f', full & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)\n",
    "print('midjet panel, correlation:')\n",
    "mean_val = np.mean(corr_ensemble_mid)\n",
    "max_val = np.max(corr_ensemble_mid)\n",
    "min_val = np.min(corr_ensemble_mid)\n",
    "std_val = np.std(corr_ensemble_mid)\n",
    "latex_table_row=f', mid & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)\n",
    "print('midjet panel, R2:')\n",
    "mean_val = np.mean(R2_ensemble_mid)\n",
    "max_val = np.max(R2_ensemble_mid)\n",
    "min_val = np.min(R2_ensemble_mid)\n",
    "std_val = np.std(R2_ensemble_mid)\n",
    "latex_table_row=f', mid & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_389418/3336474975.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3336474975.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3336474975.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3336474975.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3336474975.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3336474975.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3336474975.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3336474975.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3336474975.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/3336474975.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full panel, correlation:\n",
      ", full & 0.9456 & 0.9464 & 0.9442 & 0.0006 \\\\\n",
      "full panel, R2:\n",
      ", full & 0.8941 & 0.8956 & 0.8914 & 0.0012 \\\\\n",
      "midjet panel, correlation:\n",
      ", mid & 0.9083 & 0.9093 & 0.9057 & 0.0010 \\\\\n",
      "midjet panel, R2:\n",
      ", mid & 0.8249 & 0.8267 & 0.8201 & 0.0018 \\\\\n"
     ]
    }
   ],
   "source": [
    "# ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ Change below for each Configuration ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
    "decayunits=25 #The best SST satellite has a resolution of 9 km. It may be safe to set decayunits to be 20 km to be already resolvable by satellites\n",
    "\n",
    "vi1 = 'T_xy_ins'\n",
    "vi2 = 'u_xy_ins'\n",
    "vi3 = 'v_xy_ins'\n",
    "\n",
    "vo1 = 'ssh_cos'\n",
    "vo2 = 'ssh_sin'\n",
    "\n",
    "\n",
    "batch_size = 60 #maximizing it so that the GPU memory maxes out. Needs to be divisible by Ntrain. Otherwise there will be size mismatch issues.\n",
    "lr0 = 0.005*10/batch_size #Roughly should scale inversely to batch_size\n",
    "\n",
    "\n",
    "var_input_names = [vi1, vi2, vi3]\n",
    "var_output_names = [vo1, vo2]\n",
    "N_inp = len(var_input_names)\n",
    "N_out = len(var_output_names)\n",
    "\n",
    "save_fn_prefix  = 'any_{}{}{}_{}{}_nobatchnorm_degradeT_du_{}'.format(vi1, vi2, vi3, vo1, vo2, decayunits)\n",
    "# ↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑\n",
    "nctrains, nctest = hf.load_data_from_nc_as_lists(root_dir)\n",
    "\n",
    "all_train_input, all_train_output = preload_data_filterT(nctrains, Ntrain, decayunits=decayunits,plot=False)\n",
    "all_test_input, all_test_output = preload_data_filterT(nctest, Ntest, decayunits=decayunits,plot=False)\n",
    "\n",
    "#Normalize data\n",
    "#Compute mean and variance for normalization\n",
    "mean_input=np.nanmean(np.concatenate((all_train_input, all_test_input), axis=0),axis=(0, 2, 3))\n",
    "mean_output=np.nanmean(np.concatenate((all_train_output, all_test_output), axis=0),axis=(0, 2, 3))\n",
    "#Subtract the data with their means\n",
    "all_train_input=all_train_input-mean_input[None, :, None, None]\n",
    "all_train_output=all_train_output-mean_output[None, :, None, None]\n",
    "all_test_input=all_test_input-mean_input[None, :, None, None]\n",
    "all_test_output=all_test_output-mean_output[None, :, None, None]\n",
    "#Compute the variances\n",
    "var_input=np.nanmean((np.concatenate((all_train_input, all_test_input), axis=0))**2,axis=(0, 2, 3))\n",
    "var_output=np.nanmean((np.concatenate((all_train_output, all_test_output), axis=0))**2,axis=(0, 2, 3))\n",
    "#Scale the data so that they have variance of 1\n",
    "all_train_input=all_train_input/np.sqrt(var_input[None, :, None, None])\n",
    "all_train_output=all_train_output/np.sqrt(var_output[None, :, None, None])\n",
    "all_test_input=all_test_input/np.sqrt(var_input[None, :, None, None])\n",
    "all_test_output=all_test_output/np.sqrt(var_output[None, :, None, None])\n",
    "\n",
    "inp_test, out_test = loaddata_preloaded_test(all_test_input, all_test_output)\n",
    "out_test = out_test*np.sqrt(var_output[None, :, None, None])+mean_output[None, :, None, None]\n",
    "\n",
    "truth_bot = out_test[:, :, bottom_slice, :]\n",
    "truth_mid = out_test[:, :, mid_slice, :]\n",
    "truth_top = out_test[:, :, top_slice, :]\n",
    "\n",
    "combined_names = ''.join(var_input_names)\n",
    "\n",
    "#Array to record performance metrics\n",
    "corr_ensemble_full = np.zeros(nensemble)\n",
    "R2_ensemble_full = np.zeros(nensemble)\n",
    "corr_ensemble_top = np.zeros(nensemble)\n",
    "R2_ensemble_top = np.zeros(nensemble)\n",
    "corr_ensemble_mid = np.zeros(nensemble)\n",
    "R2_ensemble_mid = np.zeros(nensemble)\n",
    "corr_ensemble_bot = np.zeros(nensemble)\n",
    "R2_ensemble_bot = np.zeros(nensemble)\n",
    "for iensemble in np.arange(nensemble):\n",
    "    fstr = f'{save_fn_prefix}_rp_{iensemble}' \n",
    "    model_filename = f'/{fstr}.pth'\n",
    "    model_path = model_folder+ model_filename\n",
    "    state_dict = torch.load(model_path)\n",
    "    # Create a new instance of the model\n",
    "    model = UNet_nobatchnorm(N_inp, N_out, bilinear = True, Nbase = Nbase)\n",
    "    # Load the state_dict into the model\n",
    "    model.load_state_dict(state_dict)\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out_mod = model(totorch(inp_test)).detach().cpu().numpy()\n",
    "    #Renormalize\n",
    "    out_mod = out_mod*np.sqrt(var_output[None, :, None, None])+mean_output[None, :, None, None]\n",
    "\n",
    "    mod_bot = out_mod[:, :, bottom_slice, :]\n",
    "    mod_mid = out_mod[:, :, mid_slice, :]\n",
    "    mod_top = out_mod[:, :, top_slice, :]\n",
    "\n",
    "    corr_ensemble_full[iensemble] = corr(out_test, out_mod)\n",
    "    R2_ensemble_full[iensemble] = L2_R(out_test, out_mod)    \n",
    "    corr_ensemble_top[iensemble] = corr(truth_top, mod_top)\n",
    "    R2_ensemble_top[iensemble] = L2_R(truth_top, mod_top)  \n",
    "    corr_ensemble_mid[iensemble] = corr(truth_mid, mod_mid)\n",
    "    R2_ensemble_mid[iensemble] = L2_R(truth_mid, mod_mid)\n",
    "    corr_ensemble_bot[iensemble] = corr(truth_bot, mod_bot)\n",
    "    R2_ensemble_bot[iensemble] = L2_R(truth_bot, mod_bot)\n",
    "\n",
    "print('full panel, correlation:')\n",
    "mean_val = np.mean(corr_ensemble_full)\n",
    "max_val = np.max(corr_ensemble_full)\n",
    "min_val = np.min(corr_ensemble_full)\n",
    "std_val = np.std(corr_ensemble_full)\n",
    "latex_table_row=f', full & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)\n",
    "print('full panel, R2:')\n",
    "mean_val = np.mean(R2_ensemble_full)\n",
    "max_val = np.max(R2_ensemble_full)\n",
    "min_val = np.min(R2_ensemble_full)\n",
    "std_val = np.std(R2_ensemble_full)\n",
    "latex_table_row=f', full & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)\n",
    "print('midjet panel, correlation:')\n",
    "mean_val = np.mean(corr_ensemble_mid)\n",
    "max_val = np.max(corr_ensemble_mid)\n",
    "min_val = np.min(corr_ensemble_mid)\n",
    "std_val = np.std(corr_ensemble_mid)\n",
    "latex_table_row=f', mid & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)\n",
    "print('midjet panel, R2:')\n",
    "mean_val = np.mean(R2_ensemble_mid)\n",
    "max_val = np.max(R2_ensemble_mid)\n",
    "min_val = np.min(R2_ensemble_mid)\n",
    "std_val = np.std(R2_ensemble_mid)\n",
    "latex_table_row=f', mid & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_389418/2212089015.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/2212089015.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/2212089015.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/2212089015.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/2212089015.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/2212089015.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/2212089015.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/2212089015.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/2212089015.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/2212089015.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full panel, correlation:\n",
      ", full & 0.9514 & 0.9528 & 0.9492 & 0.0010 \\\\\n",
      "full panel, R2:\n",
      ", full & 0.9050 & 0.9078 & 0.9008 & 0.0020 \\\\\n",
      "midjet panel, correlation:\n",
      ", mid & 0.9183 & 0.9208 & 0.9151 & 0.0017 \\\\\n",
      "midjet panel, R2:\n",
      ", mid & 0.8432 & 0.8477 & 0.8373 & 0.0031 \\\\\n"
     ]
    }
   ],
   "source": [
    "# ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ Change below for each Configuration ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
    "decayunits=5 #The best SST satellite has a resolution of 9 km. It may be safe to set decayunits to be 20 km to be already resolvable by satellites\n",
    "\n",
    "vi1 = 'T_xy_ins'\n",
    "vi2 = 'u_xy_ins'\n",
    "vi3 = 'v_xy_ins'\n",
    "\n",
    "vo1 = 'ssh_cos'\n",
    "vo2 = 'ssh_sin'\n",
    "\n",
    "\n",
    "batch_size = 60 #maximizing it so that the GPU memory maxes out. Needs to be divisible by Ntrain. Otherwise there will be size mismatch issues.\n",
    "lr0 = 0.005*10/batch_size #Roughly should scale inversely to batch_size\n",
    "\n",
    "\n",
    "var_input_names = [vi1, vi2, vi3]\n",
    "var_output_names = [vo1, vo2]\n",
    "N_inp = len(var_input_names)\n",
    "N_out = len(var_output_names)\n",
    "\n",
    "save_fn_prefix  = 'any_{}{}{}_{}{}_nobatchnorm_degradeT_du_{}'.format(vi1, vi2, vi3, vo1, vo2, decayunits)\n",
    "# ↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑\n",
    "nctrains, nctest = hf.load_data_from_nc_as_lists(root_dir)\n",
    "\n",
    "all_train_input, all_train_output = preload_data_filterT(nctrains, Ntrain, decayunits=decayunits,plot=False)\n",
    "all_test_input, all_test_output = preload_data_filterT(nctest, Ntest, decayunits=decayunits,plot=False)\n",
    "\n",
    "#Normalize data\n",
    "#Compute mean and variance for normalization\n",
    "mean_input=np.nanmean(np.concatenate((all_train_input, all_test_input), axis=0),axis=(0, 2, 3))\n",
    "mean_output=np.nanmean(np.concatenate((all_train_output, all_test_output), axis=0),axis=(0, 2, 3))\n",
    "#Subtract the data with their means\n",
    "all_train_input=all_train_input-mean_input[None, :, None, None]\n",
    "all_train_output=all_train_output-mean_output[None, :, None, None]\n",
    "all_test_input=all_test_input-mean_input[None, :, None, None]\n",
    "all_test_output=all_test_output-mean_output[None, :, None, None]\n",
    "#Compute the variances\n",
    "var_input=np.nanmean((np.concatenate((all_train_input, all_test_input), axis=0))**2,axis=(0, 2, 3))\n",
    "var_output=np.nanmean((np.concatenate((all_train_output, all_test_output), axis=0))**2,axis=(0, 2, 3))\n",
    "#Scale the data so that they have variance of 1\n",
    "all_train_input=all_train_input/np.sqrt(var_input[None, :, None, None])\n",
    "all_train_output=all_train_output/np.sqrt(var_output[None, :, None, None])\n",
    "all_test_input=all_test_input/np.sqrt(var_input[None, :, None, None])\n",
    "all_test_output=all_test_output/np.sqrt(var_output[None, :, None, None])\n",
    "\n",
    "inp_test, out_test = loaddata_preloaded_test(all_test_input, all_test_output)\n",
    "out_test = out_test*np.sqrt(var_output[None, :, None, None])+mean_output[None, :, None, None]\n",
    "\n",
    "truth_bot = out_test[:, :, bottom_slice, :]\n",
    "truth_mid = out_test[:, :, mid_slice, :]\n",
    "truth_top = out_test[:, :, top_slice, :]\n",
    "\n",
    "combined_names = ''.join(var_input_names)\n",
    "\n",
    "#Array to record performance metrics\n",
    "corr_ensemble_full = np.zeros(nensemble)\n",
    "R2_ensemble_full = np.zeros(nensemble)\n",
    "corr_ensemble_top = np.zeros(nensemble)\n",
    "R2_ensemble_top = np.zeros(nensemble)\n",
    "corr_ensemble_mid = np.zeros(nensemble)\n",
    "R2_ensemble_mid = np.zeros(nensemble)\n",
    "corr_ensemble_bot = np.zeros(nensemble)\n",
    "R2_ensemble_bot = np.zeros(nensemble)\n",
    "for iensemble in np.arange(nensemble):\n",
    "    fstr = f'{save_fn_prefix}_rp_{iensemble}' \n",
    "    model_filename = f'/{fstr}.pth'\n",
    "    model_path = model_folder+ model_filename\n",
    "    state_dict = torch.load(model_path)\n",
    "    # Create a new instance of the model\n",
    "    model = UNet_nobatchnorm(N_inp, N_out, bilinear = True, Nbase = Nbase)\n",
    "    # Load the state_dict into the model\n",
    "    model.load_state_dict(state_dict)\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out_mod = model(totorch(inp_test)).detach().cpu().numpy()\n",
    "    #Renormalize\n",
    "    out_mod = out_mod*np.sqrt(var_output[None, :, None, None])+mean_output[None, :, None, None]\n",
    "\n",
    "    mod_bot = out_mod[:, :, bottom_slice, :]\n",
    "    mod_mid = out_mod[:, :, mid_slice, :]\n",
    "    mod_top = out_mod[:, :, top_slice, :]\n",
    "\n",
    "    corr_ensemble_full[iensemble] = corr(out_test, out_mod)\n",
    "    R2_ensemble_full[iensemble] = L2_R(out_test, out_mod)    \n",
    "    corr_ensemble_top[iensemble] = corr(truth_top, mod_top)\n",
    "    R2_ensemble_top[iensemble] = L2_R(truth_top, mod_top)  \n",
    "    corr_ensemble_mid[iensemble] = corr(truth_mid, mod_mid)\n",
    "    R2_ensemble_mid[iensemble] = L2_R(truth_mid, mod_mid)\n",
    "    corr_ensemble_bot[iensemble] = corr(truth_bot, mod_bot)\n",
    "    R2_ensemble_bot[iensemble] = L2_R(truth_bot, mod_bot)\n",
    "\n",
    "print('full panel, correlation:')\n",
    "mean_val = np.mean(corr_ensemble_full)\n",
    "max_val = np.max(corr_ensemble_full)\n",
    "min_val = np.min(corr_ensemble_full)\n",
    "std_val = np.std(corr_ensemble_full)\n",
    "latex_table_row=f', full & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)\n",
    "print('full panel, R2:')\n",
    "mean_val = np.mean(R2_ensemble_full)\n",
    "max_val = np.max(R2_ensemble_full)\n",
    "min_val = np.min(R2_ensemble_full)\n",
    "std_val = np.std(R2_ensemble_full)\n",
    "latex_table_row=f', full & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)\n",
    "print('midjet panel, correlation:')\n",
    "mean_val = np.mean(corr_ensemble_mid)\n",
    "max_val = np.max(corr_ensemble_mid)\n",
    "min_val = np.min(corr_ensemble_mid)\n",
    "std_val = np.std(corr_ensemble_mid)\n",
    "latex_table_row=f', mid & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)\n",
    "print('midjet panel, R2:')\n",
    "mean_val = np.mean(R2_ensemble_mid)\n",
    "max_val = np.max(R2_ensemble_mid)\n",
    "min_val = np.min(R2_ensemble_mid)\n",
    "std_val = np.std(R2_ensemble_mid)\n",
    "latex_table_row=f', mid & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_389418/862265290.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/862265290.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/862265290.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/862265290.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/862265290.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/862265290.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/862265290.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/862265290.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/862265290.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/862265290.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full panel, correlation:\n",
      ", full & 0.9653 & 0.9738 & 0.9510 & 0.0081 \\\\\n",
      "full panel, R2:\n",
      ", full & 0.9315 & 0.9482 & 0.9038 & 0.0155 \\\\\n",
      "midjet panel, correlation:\n",
      ", mid & 0.9438 & 0.9589 & 0.9194 & 0.0138 \\\\\n",
      "midjet panel, R2:\n",
      ", mid & 0.8903 & 0.9192 & 0.8451 & 0.0257 \\\\\n"
     ]
    }
   ],
   "source": [
    "# ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ Change below for each Configuration ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
    "decayunits=25 #The best SST satellite has a resolution of 9 km. It may be safe to set decayunits to be 20 km to be already resolvable by satellites\n",
    "\n",
    "vi1 = 'ssh_ins'\n",
    "vi2 = 'T_xy_ins'\n",
    "vi3 = 'u_xy_ins'\n",
    "vi4 = 'v_xy_ins'\n",
    "\n",
    "vo1 = 'ssh_cos'\n",
    "vo2 = 'ssh_sin'\n",
    "\n",
    "batch_size = 50 #maximizing it so that the GPU memory maxes out. Needs to be divisible by Ntrain. Otherwise there will be size mismatch issues.\n",
    "lr0 = 0.005*10/batch_size #Roughly should scale inversely to batch_size\n",
    "\n",
    "var_input_names = [vi1, vi2, vi3, vi4]\n",
    "var_output_names = [vo1, vo2]\n",
    "N_inp = len(var_input_names)\n",
    "N_out = len(var_output_names)\n",
    "\n",
    "save_fn_prefix  = 'any_{}{}{}{}_{}{}_nobatchnorm_degradeT_du_{}'.format(vi1, vi2, vi3, vi4, vo1, vo2, decayunits)\n",
    "nctrains, nctest = hf.load_data_from_nc_as_lists(root_dir)\n",
    "# ↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑\n",
    "nctrains, nctest = hf.load_data_from_nc_as_lists(root_dir)\n",
    "\n",
    "all_train_input, all_train_output = preload_data_filterT(nctrains, Ntrain, decayunits=decayunits,plot=False)\n",
    "all_test_input, all_test_output = preload_data_filterT(nctest, Ntest, decayunits=decayunits,plot=False)\n",
    "\n",
    "#Normalize data\n",
    "#Compute mean and variance for normalization\n",
    "mean_input=np.nanmean(np.concatenate((all_train_input, all_test_input), axis=0),axis=(0, 2, 3))\n",
    "mean_output=np.nanmean(np.concatenate((all_train_output, all_test_output), axis=0),axis=(0, 2, 3))\n",
    "#Subtract the data with their means\n",
    "all_train_input=all_train_input-mean_input[None, :, None, None]\n",
    "all_train_output=all_train_output-mean_output[None, :, None, None]\n",
    "all_test_input=all_test_input-mean_input[None, :, None, None]\n",
    "all_test_output=all_test_output-mean_output[None, :, None, None]\n",
    "#Compute the variances\n",
    "var_input=np.nanmean((np.concatenate((all_train_input, all_test_input), axis=0))**2,axis=(0, 2, 3))\n",
    "var_output=np.nanmean((np.concatenate((all_train_output, all_test_output), axis=0))**2,axis=(0, 2, 3))\n",
    "#Scale the data so that they have variance of 1\n",
    "all_train_input=all_train_input/np.sqrt(var_input[None, :, None, None])\n",
    "all_train_output=all_train_output/np.sqrt(var_output[None, :, None, None])\n",
    "all_test_input=all_test_input/np.sqrt(var_input[None, :, None, None])\n",
    "all_test_output=all_test_output/np.sqrt(var_output[None, :, None, None])\n",
    "\n",
    "inp_test, out_test = loaddata_preloaded_test(all_test_input, all_test_output)\n",
    "out_test = out_test*np.sqrt(var_output[None, :, None, None])+mean_output[None, :, None, None]\n",
    "\n",
    "truth_bot = out_test[:, :, bottom_slice, :]\n",
    "truth_mid = out_test[:, :, mid_slice, :]\n",
    "truth_top = out_test[:, :, top_slice, :]\n",
    "\n",
    "combined_names = ''.join(var_input_names)\n",
    "\n",
    "#Array to record performance metrics\n",
    "corr_ensemble_full = np.zeros(nensemble)\n",
    "R2_ensemble_full = np.zeros(nensemble)\n",
    "corr_ensemble_top = np.zeros(nensemble)\n",
    "R2_ensemble_top = np.zeros(nensemble)\n",
    "corr_ensemble_mid = np.zeros(nensemble)\n",
    "R2_ensemble_mid = np.zeros(nensemble)\n",
    "corr_ensemble_bot = np.zeros(nensemble)\n",
    "R2_ensemble_bot = np.zeros(nensemble)\n",
    "for iensemble in np.arange(nensemble):\n",
    "    fstr = f'{save_fn_prefix}_rp_{iensemble}' \n",
    "    model_filename = f'/{fstr}.pth'\n",
    "    model_path = model_folder+ model_filename\n",
    "    state_dict = torch.load(model_path)\n",
    "    # Create a new instance of the model\n",
    "    model = UNet_nobatchnorm(N_inp, N_out, bilinear = True, Nbase = Nbase)\n",
    "    # Load the state_dict into the model\n",
    "    model.load_state_dict(state_dict)\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out_mod = model(totorch(inp_test)).detach().cpu().numpy()\n",
    "    #Renormalize\n",
    "    out_mod = out_mod*np.sqrt(var_output[None, :, None, None])+mean_output[None, :, None, None]\n",
    "\n",
    "    mod_bot = out_mod[:, :, bottom_slice, :]\n",
    "    mod_mid = out_mod[:, :, mid_slice, :]\n",
    "    mod_top = out_mod[:, :, top_slice, :]\n",
    "\n",
    "    corr_ensemble_full[iensemble] = corr(out_test, out_mod)\n",
    "    R2_ensemble_full[iensemble] = L2_R(out_test, out_mod)    \n",
    "    corr_ensemble_top[iensemble] = corr(truth_top, mod_top)\n",
    "    R2_ensemble_top[iensemble] = L2_R(truth_top, mod_top)  \n",
    "    corr_ensemble_mid[iensemble] = corr(truth_mid, mod_mid)\n",
    "    R2_ensemble_mid[iensemble] = L2_R(truth_mid, mod_mid)\n",
    "    corr_ensemble_bot[iensemble] = corr(truth_bot, mod_bot)\n",
    "    R2_ensemble_bot[iensemble] = L2_R(truth_bot, mod_bot)\n",
    "\n",
    "print('full panel, correlation:')\n",
    "mean_val = np.mean(corr_ensemble_full)\n",
    "max_val = np.max(corr_ensemble_full)\n",
    "min_val = np.min(corr_ensemble_full)\n",
    "std_val = np.std(corr_ensemble_full)\n",
    "latex_table_row=f', full & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)\n",
    "print('full panel, R2:')\n",
    "mean_val = np.mean(R2_ensemble_full)\n",
    "max_val = np.max(R2_ensemble_full)\n",
    "min_val = np.min(R2_ensemble_full)\n",
    "std_val = np.std(R2_ensemble_full)\n",
    "latex_table_row=f', full & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)\n",
    "print('midjet panel, correlation:')\n",
    "mean_val = np.mean(corr_ensemble_mid)\n",
    "max_val = np.max(corr_ensemble_mid)\n",
    "min_val = np.min(corr_ensemble_mid)\n",
    "std_val = np.std(corr_ensemble_mid)\n",
    "latex_table_row=f', mid & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)\n",
    "print('midjet panel, R2:')\n",
    "mean_val = np.mean(R2_ensemble_mid)\n",
    "max_val = np.max(R2_ensemble_mid)\n",
    "min_val = np.min(R2_ensemble_mid)\n",
    "std_val = np.std(R2_ensemble_mid)\n",
    "latex_table_row=f', mid & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_389418/482931383.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/482931383.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/482931383.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/482931383.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/482931383.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/482931383.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/482931383.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/482931383.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/482931383.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n",
      "/tmp/ipykernel_389418/482931383.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full panel, correlation:\n",
      ", full & 0.9671 & 0.9738 & 0.9604 & 0.0042 \\\\\n",
      "full panel, R2:\n",
      ", full & 0.9350 & 0.9484 & 0.9220 & 0.0082 \\\\\n",
      "midjet panel, correlation:\n",
      ", mid & 0.9471 & 0.9587 & 0.9349 & 0.0075 \\\\\n",
      "midjet panel, R2:\n",
      ", mid & 0.8964 & 0.9189 & 0.8736 & 0.0141 \\\\\n"
     ]
    }
   ],
   "source": [
    "# ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ Change below for each Configuration ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
    "decayunits=5 #The best SST satellite has a resolution of 9 km. It may be safe to set decayunits to be 20 km to be already resolvable by satellites\n",
    "\n",
    "vi1 = 'ssh_ins'\n",
    "vi2 = 'T_xy_ins'\n",
    "vi3 = 'u_xy_ins'\n",
    "vi4 = 'v_xy_ins'\n",
    "\n",
    "vo1 = 'ssh_cos'\n",
    "vo2 = 'ssh_sin'\n",
    "\n",
    "batch_size = 50 #maximizing it so that the GPU memory maxes out. Needs to be divisible by Ntrain. Otherwise there will be size mismatch issues.\n",
    "lr0 = 0.005*10/batch_size #Roughly should scale inversely to batch_size\n",
    "\n",
    "var_input_names = [vi1, vi2, vi3, vi4]\n",
    "var_output_names = [vo1, vo2]\n",
    "N_inp = len(var_input_names)\n",
    "N_out = len(var_output_names)\n",
    "\n",
    "save_fn_prefix  = 'any_{}{}{}{}_{}{}_nobatchnorm_degradeT_du_{}'.format(vi1, vi2, vi3, vi4, vo1, vo2, decayunits)\n",
    "nctrains, nctest = hf.load_data_from_nc_as_lists(root_dir)\n",
    "# ↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑\n",
    "nctrains, nctest = hf.load_data_from_nc_as_lists(root_dir)\n",
    "\n",
    "all_train_input, all_train_output = preload_data_filterT(nctrains, Ntrain, decayunits=decayunits,plot=False)\n",
    "all_test_input, all_test_output = preload_data_filterT(nctest, Ntest, decayunits=decayunits,plot=False)\n",
    "\n",
    "#Normalize data\n",
    "#Compute mean and variance for normalization\n",
    "mean_input=np.nanmean(np.concatenate((all_train_input, all_test_input), axis=0),axis=(0, 2, 3))\n",
    "mean_output=np.nanmean(np.concatenate((all_train_output, all_test_output), axis=0),axis=(0, 2, 3))\n",
    "#Subtract the data with their means\n",
    "all_train_input=all_train_input-mean_input[None, :, None, None]\n",
    "all_train_output=all_train_output-mean_output[None, :, None, None]\n",
    "all_test_input=all_test_input-mean_input[None, :, None, None]\n",
    "all_test_output=all_test_output-mean_output[None, :, None, None]\n",
    "#Compute the variances\n",
    "var_input=np.nanmean((np.concatenate((all_train_input, all_test_input), axis=0))**2,axis=(0, 2, 3))\n",
    "var_output=np.nanmean((np.concatenate((all_train_output, all_test_output), axis=0))**2,axis=(0, 2, 3))\n",
    "#Scale the data so that they have variance of 1\n",
    "all_train_input=all_train_input/np.sqrt(var_input[None, :, None, None])\n",
    "all_train_output=all_train_output/np.sqrt(var_output[None, :, None, None])\n",
    "all_test_input=all_test_input/np.sqrt(var_input[None, :, None, None])\n",
    "all_test_output=all_test_output/np.sqrt(var_output[None, :, None, None])\n",
    "\n",
    "inp_test, out_test = loaddata_preloaded_test(all_test_input, all_test_output)\n",
    "out_test = out_test*np.sqrt(var_output[None, :, None, None])+mean_output[None, :, None, None]\n",
    "\n",
    "truth_bot = out_test[:, :, bottom_slice, :]\n",
    "truth_mid = out_test[:, :, mid_slice, :]\n",
    "truth_top = out_test[:, :, top_slice, :]\n",
    "\n",
    "combined_names = ''.join(var_input_names)\n",
    "\n",
    "#Array to record performance metrics\n",
    "corr_ensemble_full = np.zeros(nensemble)\n",
    "R2_ensemble_full = np.zeros(nensemble)\n",
    "corr_ensemble_top = np.zeros(nensemble)\n",
    "R2_ensemble_top = np.zeros(nensemble)\n",
    "corr_ensemble_mid = np.zeros(nensemble)\n",
    "R2_ensemble_mid = np.zeros(nensemble)\n",
    "corr_ensemble_bot = np.zeros(nensemble)\n",
    "R2_ensemble_bot = np.zeros(nensemble)\n",
    "for iensemble in np.arange(nensemble):\n",
    "    fstr = f'{save_fn_prefix}_rp_{iensemble}' \n",
    "    model_filename = f'/{fstr}.pth'\n",
    "    model_path = model_folder+ model_filename\n",
    "    state_dict = torch.load(model_path)\n",
    "    # Create a new instance of the model\n",
    "    model = UNet_nobatchnorm(N_inp, N_out, bilinear = True, Nbase = Nbase)\n",
    "    # Load the state_dict into the model\n",
    "    model.load_state_dict(state_dict)\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out_mod = model(totorch(inp_test)).detach().cpu().numpy()\n",
    "    #Renormalize\n",
    "    out_mod = out_mod*np.sqrt(var_output[None, :, None, None])+mean_output[None, :, None, None]\n",
    "\n",
    "    mod_bot = out_mod[:, :, bottom_slice, :]\n",
    "    mod_mid = out_mod[:, :, mid_slice, :]\n",
    "    mod_top = out_mod[:, :, top_slice, :]\n",
    "\n",
    "    corr_ensemble_full[iensemble] = corr(out_test, out_mod)\n",
    "    R2_ensemble_full[iensemble] = L2_R(out_test, out_mod)    \n",
    "    corr_ensemble_top[iensemble] = corr(truth_top, mod_top)\n",
    "    R2_ensemble_top[iensemble] = L2_R(truth_top, mod_top)  \n",
    "    corr_ensemble_mid[iensemble] = corr(truth_mid, mod_mid)\n",
    "    R2_ensemble_mid[iensemble] = L2_R(truth_mid, mod_mid)\n",
    "    corr_ensemble_bot[iensemble] = corr(truth_bot, mod_bot)\n",
    "    R2_ensemble_bot[iensemble] = L2_R(truth_bot, mod_bot)\n",
    "\n",
    "print('full panel, correlation:')\n",
    "mean_val = np.mean(corr_ensemble_full)\n",
    "max_val = np.max(corr_ensemble_full)\n",
    "min_val = np.min(corr_ensemble_full)\n",
    "std_val = np.std(corr_ensemble_full)\n",
    "latex_table_row=f', full & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)\n",
    "print('full panel, R2:')\n",
    "mean_val = np.mean(R2_ensemble_full)\n",
    "max_val = np.max(R2_ensemble_full)\n",
    "min_val = np.min(R2_ensemble_full)\n",
    "std_val = np.std(R2_ensemble_full)\n",
    "latex_table_row=f', full & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)\n",
    "print('midjet panel, correlation:')\n",
    "mean_val = np.mean(corr_ensemble_mid)\n",
    "max_val = np.max(corr_ensemble_mid)\n",
    "min_val = np.min(corr_ensemble_mid)\n",
    "std_val = np.std(corr_ensemble_mid)\n",
    "latex_table_row=f', mid & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)\n",
    "print('midjet panel, R2:')\n",
    "mean_val = np.mean(R2_ensemble_mid)\n",
    "max_val = np.max(R2_ensemble_mid)\n",
    "min_val = np.min(R2_ensemble_mid)\n",
    "std_val = np.std(R2_ensemble_mid)\n",
    "latex_table_row=f', mid & {mean_val:.4f} & {max_val:.4f} & {min_val:.4f} & {std_val:.4f} \\\\\\\\'\n",
    "print(latex_table_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML (based on the latest module pytorch)",
   "language": "python",
   "name": "ml-aim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b958b4221dbd89eccc41b3ab284a3e7443193eeb047d11fe6a91aac279bd724"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
